{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "plastic-turner",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/nalinjindal/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import snowball\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "interested-panel",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('Scraping reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "intense-decade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n\\n  Please do not buy expensive product like...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n\\n  Bought the mobile from appario retail lt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n\\n  Awesome Phone. Nice upgrade from iPhone ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\n\\n  My Phone is Producing Too Much Heat Even...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\n\\n  This is a big scam. I received the iphon...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviews\n",
       "0  \\n\\n  Please do not buy expensive product like...\n",
       "1  \\n\\n  Bought the mobile from appario retail lt...\n",
       "2  \\n\\n  Awesome Phone. Nice upgrade from iPhone ...\n",
       "3  \\n\\n  My Phone is Producing Too Much Heat Even...\n",
       "4  \\n\\n  This is a big scam. I received the iphon..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "descending-stanford",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22308, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "saving-extra",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'weren', 'more', 'other', 'it', 'will', 'don', \"isn't\", 'up', 'mustn', \"that'll\", 's', 'should', 'once', 'some', 'wasn', 'below', 'that', 'than', 'then', 're', 'ourselves', 'each', 'but', 'such', 'do', 'for', \"you'd\", 'was', \"doesn't\", 'between', 'my', \"you'll\", \"it's\", 'be', 've', 'ma', 'myself', 'been', 'not', 'is', 'having', 'yourself', \"she's\", \"mightn't\", 'after', 'are', 'until', \"don't\", 'we', 'with', 'being', 'few', \"should've\", \"needn't\", 'hers', 'a', 'our', 't', 'y', 'an', 'there', 'own', 'its', 'same', 'you', 'they', 'just', 'now', \"aren't\", 'as', 'themselves', 'at', 'them', 'most', 'ours', 'who', 'aren', \"didn't\", \"haven't\", 'hadn', 'under', 'yours', 'does', 'haven', 'this', 'too', 'did', 'theirs', 'during', 'by', 'how', 'both', 'himself', \"couldn't\", 'why', 'hasn', 'can', 'so', 'am', 'from', 'couldn', 'll', 'over', 'shan', 'herself', 'into', 'mightn', \"hadn't\", 'yourselves', 'only', 'were', \"you're\", 'his', 'any', 'shouldn', 'down', 'and', 'me', 'in', 'doesn', 'doing', 'm', 'again', 'if', 'on', 'these', 'whom', 'while', \"won't\", 'to', 'when', 'out', 'him', 'where', 'nor', \"you've\", 'very', 'itself', 'your', 'wouldn', 'have', 'because', \"wasn't\", 'won', 'before', 'further', \"wouldn't\", \"shan't\", 'has', 'or', \"mustn't\", 'those', 'd', 'which', \"hasn't\", 'off', 'needn', 'i', 'all', 'their', 'no', 'isn', 'above', 'had', 'he', 'through', 'what', 'here', 'her', 'o', 'didn', \"shouldn't\", 'the', 'ain', 'about', 'against', 'she', \"weren't\", 'of'}\n"
     ]
    }
   ],
   "source": [
    "stop=set(stopwords.words('english'))\n",
    "print(stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "tracked-longer",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "import numpy\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "stop=set(stopwords.words('english'))\n",
    "snow = nltk.stem.SnowballStemmer('english')\n",
    "stop\n",
    "def decontracted(phrase):\n",
    "    phrase=re.sub(r\"won't\",\"will not\",phrase)\n",
    "    phrase=re.sub(r\"can't\",\"can not\",phrase)\n",
    "    phrase=re.sub(r\"n\\'t\",\"not\",phrase)\n",
    "    phrase=re.sub(r\"\\'re\",\"are\",phrase)\n",
    "    phrase=re.sub(r\"\\'s\",\"is\",phrase)\n",
    "    phrase=re.sub(r\"\\'d\",\"would\",phrase)\n",
    "    phrase=re.sub(r\"\\'ll\",\"will\",phrase)    \n",
    "    phrase=re.sub(r\"\\'t\",\"not\",sentence)\n",
    "    phrase=re.sub(r\"\\'ve\",\"have\",sentence)\n",
    "    phrase=re.sub(r\"\\'m\",\"am\",sentence)\n",
    "    return phrase\n",
    "preprocessed_reviews=[]\n",
    "for sentence in data['reviews'].values:\n",
    "    sentence=re.sub(r\"http\\S+\",\" \",sentence)\n",
    "    sentence=BeautifulSoup(sentence,'lxml').get_text()\n",
    "    cleanr=re.compile('<.*?>')\n",
    "    sentence=re.sub(cleanr,' ',sentence)\n",
    "    sentence=decontracted(sentence)\n",
    "    sentence=re.sub(\"\\S\\*\\d\\S*\",\" \",sentence)\n",
    "    sentence=re.sub(\"[^A-Za-z]+\",\" \",sentence)\n",
    "    sentence=re.sub(r'[?|!|\\'|\"|#]',r' ',sentence)\n",
    "    sentence=re.sub(r'[.|,|)|(|\\|/]',r' ',sentence)\n",
    "    sentence='  '.join(snow.stem(e.lower()) for e in sentence.split() if e.lower() not in stop)\n",
    "    preprocessed_reviews.append(sentence.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "physical-married",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'first  io  devic  use  oneplus  devic  expect  pretti  high  iphon  iphon  liter  surpass  expect  proven  best  decis  made  batteri  life  camera  qualiti  simplic  ui  everyth  els  worth  experienc  got  phone  gb  sale  paid  cost  emi  month  price  amazon  k  less  market  price  deliveri  fast  phone  handl  right  way'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_reviews[1700]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "global-hopkins",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 7369)\t1\n",
      "  (0, 1414)\t1\n",
      "  (0, 7672)\t1\n",
      "  (0, 310)\t1\n",
      "  (0, 5029)\t1\n",
      "  (0, 10071)\t1\n",
      "  (0, 352)\t1\n",
      "  (0, 1253)\t1\n",
      "  (0, 6132)\t2\n",
      "  (0, 458)\t1\n",
      "  (0, 8384)\t1\n",
      "  (0, 5712)\t1\n",
      "  (0, 4459)\t1\n",
      "  (0, 11008)\t1\n",
      "  (0, 8760)\t1\n",
      "  (0, 270)\t1\n",
      "  (0, 1481)\t1\n",
      "  (0, 6164)\t2\n",
      "  (0, 11042)\t2\n",
      "  (0, 7751)\t2\n",
      "  (0, 7017)\t1\n",
      "  (0, 7464)\t1\n",
      "  (0, 9399)\t1\n",
      "  (0, 5538)\t1\n",
      "  (0, 6228)\t1\n",
      "  :\t:\n",
      "  (0, 1642)\t2\n",
      "  (0, 6431)\t1\n",
      "  (0, 5612)\t1\n",
      "  (0, 5298)\t1\n",
      "  (0, 7336)\t1\n",
      "  (0, 4758)\t1\n",
      "  (0, 9509)\t1\n",
      "  (0, 6335)\t1\n",
      "  (0, 4058)\t1\n",
      "  (0, 2214)\t1\n",
      "  (0, 433)\t1\n",
      "  (0, 8799)\t3\n",
      "  (0, 4172)\t1\n",
      "  (0, 3596)\t2\n",
      "  (0, 6601)\t1\n",
      "  (0, 2033)\t1\n",
      "  (0, 3213)\t1\n",
      "  (0, 8798)\t1\n",
      "  (0, 2480)\t1\n",
      "  (0, 9978)\t1\n",
      "  (0, 2949)\t1\n",
      "  (0, 2430)\t1\n",
      "  (0, 7964)\t1\n",
      "  (0, 8554)\t1\n",
      "  (0, 8236)\t1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count=CountVectorizer()\n",
    "Reviews_BOW=count.fit_transform(preprocessed_reviews)\n",
    "print(Reviews_BOW[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "recreational-company",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 95905)\t1\n",
      "  (0, 17146)\t1\n",
      "  (0, 100233)\t1\n",
      "  (0, 3784)\t1\n",
      "  (0, 64877)\t1\n",
      "  (0, 131264)\t1\n",
      "  (0, 4580)\t1\n",
      "  (0, 64891)\t1\n",
      "  (0, 15007)\t1\n",
      "  (0, 78310)\t2\n",
      "  (0, 6229)\t1\n",
      "  (0, 109658)\t1\n",
      "  (0, 73352)\t1\n",
      "  (0, 57856)\t1\n",
      "  (0, 141883)\t1\n",
      "  (0, 114329)\t1\n",
      "  (0, 2518)\t1\n",
      "  (0, 18522)\t1\n",
      "  (0, 79040)\t2\n",
      "  (0, 142367)\t2\n",
      "  (0, 101201)\t2\n",
      "  (0, 90531)\t1\n",
      "  (0, 97232)\t1\n",
      "  (0, 123206)\t1\n",
      "  (0, 69736)\t1\n",
      "  :\t:\n",
      "  (0, 4640)\t1\n",
      "  (0, 124680)\t1\n",
      "  (0, 81394)\t1\n",
      "  (0, 52403)\t1\n",
      "  (0, 28449)\t1\n",
      "  (0, 17168)\t1\n",
      "  (0, 5551)\t1\n",
      "  (0, 115480)\t1\n",
      "  (0, 54260)\t1\n",
      "  (0, 46137)\t1\n",
      "  (0, 85284)\t1\n",
      "  (0, 26345)\t1\n",
      "  (0, 115465)\t1\n",
      "  (0, 40553)\t1\n",
      "  (0, 115373)\t1\n",
      "  (0, 46085)\t1\n",
      "  (0, 31967)\t1\n",
      "  (0, 100809)\t1\n",
      "  (0, 130034)\t1\n",
      "  (0, 115458)\t1\n",
      "  (0, 37027)\t1\n",
      "  (0, 31339)\t1\n",
      "  (0, 103979)\t1\n",
      "  (0, 96008)\t1\n",
      "  (0, 111242)\t1\n"
     ]
    }
   ],
   "source": [
    "count=CountVectorizer(ngram_range=(1,2))\n",
    "Bigram_Counts=count.fit_transform(preprocessed_reviews)\n",
    "print(Bigram_Counts[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "immediate-alcohol",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 8236)\t0.10295346778206306\n",
      "  (0, 8554)\t0.12224910615084508\n",
      "  (0, 7964)\t0.17347057500832713\n",
      "  (0, 2430)\t0.09756462820805249\n",
      "  (0, 2949)\t0.18934713103016002\n",
      "  (0, 9978)\t0.16861448120050876\n",
      "  (0, 2480)\t0.09649592458038232\n",
      "  (0, 8798)\t0.1036266076723118\n",
      "  (0, 3213)\t0.08807943255610823\n",
      "  (0, 2033)\t0.10737789501407495\n",
      "  (0, 6601)\t0.15693912463065546\n",
      "  (0, 3596)\t0.17760786382472546\n",
      "  (0, 4172)\t0.10414665390444479\n",
      "  (0, 8799)\t0.3012508053254889\n",
      "  (0, 433)\t0.10121058370769626\n",
      "  (0, 2214)\t0.09170857471370565\n",
      "  (0, 4058)\t0.059657196448686736\n",
      "  (0, 6335)\t0.06596631399311852\n",
      "  (0, 9509)\t0.15465711255034964\n",
      "  (0, 4758)\t0.1348172187114122\n",
      "  (0, 7336)\t0.10146515380545444\n",
      "  (0, 5298)\t0.15693912463065546\n",
      "  (0, 5612)\t0.12804193753192006\n",
      "  (0, 6431)\t0.15326785646075763\n",
      "  (0, 1642)\t0.20044663210776428\n",
      "  :\t:\n",
      "  (0, 6228)\t0.16355395694101893\n",
      "  (0, 5538)\t0.0713789588731273\n",
      "  (0, 9399)\t0.14601875985492216\n",
      "  (0, 7464)\t0.11943482801814527\n",
      "  (0, 7017)\t0.12328195954638199\n",
      "  (0, 7751)\t0.18241963829424473\n",
      "  (0, 11042)\t0.11461383783825567\n",
      "  (0, 6164)\t0.1547519720331022\n",
      "  (0, 1481)\t0.0370465385785632\n",
      "  (0, 270)\t0.056319569199397915\n",
      "  (0, 8760)\t0.09376711369022334\n",
      "  (0, 11008)\t0.09057340687292567\n",
      "  (0, 4459)\t0.06999046945438522\n",
      "  (0, 5712)\t0.141808440046539\n",
      "  (0, 8384)\t0.12502028139187707\n",
      "  (0, 458)\t0.12389685393567888\n",
      "  (0, 6132)\t0.11488920611159843\n",
      "  (0, 1253)\t0.07408256818906561\n",
      "  (0, 352)\t0.1096296910745386\n",
      "  (0, 10071)\t0.11305651039672064\n",
      "  (0, 5029)\t0.061919172225437795\n",
      "  (0, 310)\t0.06036999978798061\n",
      "  (0, 7672)\t0.05376662009243478\n",
      "  (0, 1414)\t0.05514594513413834\n",
      "  (0, 7369)\t0.0825385559302232\n"
     ]
    }
   ],
   "source": [
    "counts=TfidfVectorizer()\n",
    "cnt=counts.fit_transform(preprocessed_reviews)\n",
    "print(cnt[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "possible-blackjack",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22308\n",
      "[-0.61607372  0.20312698 -0.16679208  0.20253471  0.1003344  -0.29386663\n",
      " -0.22502044 -0.11107483 -0.66683408 -0.66840911  1.01009651 -0.48525575\n",
      "  0.16518139  0.74913443  0.21055997  0.1489747  -0.19142982 -0.22133344\n",
      "  0.06672649  0.85636391  0.05697902 -0.17763137  0.1939312  -0.3466857\n",
      "  0.01962107  0.23604062  0.10595884  0.39775508  0.26604376 -0.91141786\n",
      " -0.17965551 -0.93052141 -0.44600644 -0.17622445  0.38718457  0.83984039\n",
      " -0.52669672  0.15748714 -0.28169215  0.01014395  0.35488324 -0.0742711\n",
      " -0.76855385 -0.0643742  -0.73685926  0.26476465  0.31067509  0.16671656\n",
      " -0.20693536  0.37781333]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "list_of_sentences=[]\n",
    "for sentence in preprocessed_reviews:\n",
    "    list_of_sentences.append(sentence.split())\n",
    "w2v_model=Word2Vec(list_of_sentences,min_count=5,size=50,workers=4)\n",
    "w2v_words=list(w2v_model.wv.vocab)\n",
    "sent_vectors=[]\n",
    "for sent in list_of_sentences:\n",
    "    sent_vec=np.zeros(50)\n",
    "    cnt_words=0\n",
    "    for word in sent:\n",
    "        if word in w2v_words:\n",
    "            vec=w2v_model.wv[word]\n",
    "            sent_vec=sent_vec+vec\n",
    "            cnt_words=cnt_words+1\n",
    "    if cnt_words!=0:\n",
    "        sent_vec=sent_vec/cnt_words\n",
    "    sent_vectors.append(sent_vec)\n",
    "print(len(sent_vectors))   \n",
    "print(sent_vectors[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "increased-authentication",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
